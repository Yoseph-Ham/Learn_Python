{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\has91\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1143.38x1000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder # 전처리\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "df = pd.read_csv('../data/iris.csv',\n",
    "                names=['sepal_length', 'sepal_width', 'petal_lengh', 'petal_width',\n",
    "                      'species'])\n",
    "\n",
    "# 그래프로 확인\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분류\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:4].astype(float) #숫자\n",
    "Y_obj = dataset[:,4] # 문자열\n",
    "\n",
    "# LabelENcoder를 이용해 문자열을 숫자로 변환\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "print(Y)\n",
    "\n",
    "Y_encoded = tf.keras.utils.to_categorical(Y) # 활성화 함수 적용\n",
    "print(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 606us/step - loss: 1.4214 - accuracy: 0.3200\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 547us/step - loss: 0.8921 - accuracy: 0.5467\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 574us/step - loss: 0.7284 - accuracy: 0.7000\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.6266 - accuracy: 0.6933\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 665us/step - loss: 0.5578 - accuracy: 0.7067\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 619us/step - loss: 0.5026 - accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 592us/step - loss: 0.4616 - accuracy: 0.8800\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 625us/step - loss: 0.4358 - accuracy: 0.8933\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 623us/step - loss: 0.4078 - accuracy: 0.9267\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 617us/step - loss: 0.3846 - accuracy: 0.9533\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 578us/step - loss: 0.3606 - accuracy: 0.9067\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 599us/step - loss: 0.3371 - accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 632us/step - loss: 0.3284 - accuracy: 0.9400\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 625us/step - loss: 0.3046 - accuracy: 0.9533\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 785us/step - loss: 0.2883 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 791us/step - loss: 0.2731 - accuracy: 0.9533\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 632us/step - loss: 0.2625 - accuracy: 0.9400\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 565us/step - loss: 0.2567 - accuracy: 0.9467\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.2356 - accuracy: 0.9600\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 592us/step - loss: 0.2238 - accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 525us/step - loss: 0.2154 - accuracy: 0.9800\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 553us/step - loss: 0.2101 - accuracy: 0.9600\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 551us/step - loss: 0.1969 - accuracy: 0.9733\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 667us/step - loss: 0.1922 - accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 578us/step - loss: 0.1799 - accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 606us/step - loss: 0.1742 - accuracy: 0.9733\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 612us/step - loss: 0.1695 - accuracy: 0.9733\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 585us/step - loss: 0.1515 - accuracy: 0.9867\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 602us/step - loss: 0.1580 - accuracy: 0.9600\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 602us/step - loss: 0.1552 - accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 603us/step - loss: 0.1478 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 541us/step - loss: 0.1428 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 611us/step - loss: 0.1375 - accuracy: 0.9667\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 559us/step - loss: 0.1326 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 577us/step - loss: 0.1303 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 635us/step - loss: 0.1293 - accuracy: 0.9533\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 685us/step - loss: 0.1197 - accuracy: 0.9600\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 644us/step - loss: 0.1226 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.1150 - accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 651us/step - loss: 0.1222 - accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.1121 - accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 635us/step - loss: 0.1115 - accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 580us/step - loss: 0.1099 - accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 574us/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 560us/step - loss: 0.1128 - accuracy: 0.9533\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 563us/step - loss: 0.1060 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 669us/step - loss: 0.1056 - accuracy: 0.9600\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 658us/step - loss: 0.1013 - accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 665us/step - loss: 0.0993 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 672us/step - loss: 0.1055 - accuracy: 0.9533\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0929 - accuracy: 0.9733\n",
      "\n",
      " Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu')) # input 4\n",
    "model.add(Dense(3, activation='softmax')) #출력값 3, softmax\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(X, Y_encoded, epochs=50, batch_size=1)\n",
    "\n",
    "# 결과 출력\n",
    "print('\\n Accuracy: %.4f' %(model.evaluate(X, Y_encoded)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
